{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = 'images/'\n",
    "\n",
    "#Normalize images - divide by 255\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#Resize images, if needed\n",
    "train = train_datagen.flow_from_directory(path, \n",
    "                                          target_size=(256, 256), \n",
    "                                          batch_size=340, \n",
    "                                          class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 256, 256, 1)\n",
      "(3, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "#Convert from RGB to Lab\n",
    "\"\"\"\n",
    "by iterating on each image, we convert the RGB to Lab. \n",
    "Think of LAB image as a grey image in L channel and all color info stored in A and B channels. \n",
    "The input to the network will be the L channel, so we assign L channel to X vector. \n",
    "And assign A and B to Y.\n",
    "\"\"\"\n",
    "\n",
    "X =[]\n",
    "Y =[]\n",
    "for img in train[0]:\n",
    "    try:\n",
    "        lab = rgb2lab(img)\n",
    "        X.append(lab[:,:,0]) \n",
    "        Y.append(lab[:,:,1:] / 128) #A and B values range from -127 to 128, \n",
    "        #so we divide the values by 128 to restrict values to between -1 and 1.\n",
    "    except:\n",
    "        print('error')\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(X.shape+(1,)) #dimensions to be the same for X and Y\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 128)       295040    \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 128, 32)      18464     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 16)      4624      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 128, 128, 2)       290       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 256, 256, 2)       0         \n",
      "=================================================================\n",
      "Total params: 6,219,410\n",
      "Trainable params: 6,219,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Encoder\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2, input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "#Decoder\n",
    "#Decoder\n",
    "#Note: For the last layer we use tanh instead of Relu. \n",
    "#This is because we are colorizing the image in this layer using 2 filters, A and B.\n",
    "#A and B values range between -1 and 1 so tanh (or hyperbolic tangent) is used\n",
    "#as it also has the range between -1 and 1. \n",
    "#Other functions go from 0 to 1.\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0044 - accuracy: 0.8915 - val_loss: 0.0268 - val_accuracy: 0.7451\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 887ms/step - loss: 0.0042 - accuracy: 0.8870 - val_loss: 0.0258 - val_accuracy: 0.7447\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0041 - accuracy: 0.8905 - val_loss: 0.0215 - val_accuracy: 0.7369\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 0.0041 - accuracy: 0.8938 - val_loss: 0.0317 - val_accuracy: 0.7436\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0042 - accuracy: 0.8923 - val_loss: 0.0160 - val_accuracy: 0.7231\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0047 - accuracy: 0.8909 - val_loss: 0.0310 - val_accuracy: 0.7479\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0040 - accuracy: 0.8961 - val_loss: 0.0262 - val_accuracy: 0.7470\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.0038 - accuracy: 0.8981 - val_loss: 0.0202 - val_accuracy: 0.7408\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.0039 - accuracy: 0.8986 - val_loss: 0.0310 - val_accuracy: 0.7469\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0037 - accuracy: 0.8984 - val_loss: 0.0232 - val_accuracy: 0.7395\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 0.0035 - accuracy: 0.9015 - val_loss: 0.0254 - val_accuracy: 0.7410\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0034 - accuracy: 0.9030 - val_loss: 0.0302 - val_accuracy: 0.7416\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0033 - accuracy: 0.9041 - val_loss: 0.0217 - val_accuracy: 0.7224\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - accuracy: 0.9015 - val_loss: 0.0340 - val_accuracy: 0.7526\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - accuracy: 0.8934 - val_loss: 0.0193 - val_accuracy: 0.7398\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - accuracy: 0.9061 - val_loss: 0.0261 - val_accuracy: 0.7402\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030 - accuracy: 0.9038 - val_loss: 0.0367 - val_accuracy: 0.7430\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0034 - accuracy: 0.9010 - val_loss: 0.0182 - val_accuracy: 0.7258\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0036 - accuracy: 0.9063 - val_loss: 0.0248 - val_accuracy: 0.7412\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0033 - accuracy: 0.9082 - val_loss: 0.0311 - val_accuracy: 0.7343\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030 - accuracy: 0.9066 - val_loss: 0.0285 - val_accuracy: 0.7027\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0041 - accuracy: 0.8898 - val_loss: 0.0314 - val_accuracy: 0.7575\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0040 - accuracy: 0.8814 - val_loss: 0.0148 - val_accuracy: 0.7480\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0045 - accuracy: 0.9009 - val_loss: 0.0223 - val_accuracy: 0.7540\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0036 - accuracy: 0.8954 - val_loss: 0.0445 - val_accuracy: 0.7595\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0056 - accuracy: 0.8726 - val_loss: 0.0106 - val_accuracy: 0.7246\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060 - accuracy: 0.8996 - val_loss: 0.0162 - val_accuracy: 0.7397\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0043 - accuracy: 0.8995 - val_loss: 0.0711 - val_accuracy: 0.7659\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0120 - accuracy: 0.8417 - val_loss: 0.0086 - val_accuracy: 0.7349\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0067 - accuracy: 0.9033 - val_loss: 0.0055 - val_accuracy: 0.7267\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0092 - accuracy: 0.8885 - val_loss: 0.0138 - val_accuracy: 0.7548\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0065 - accuracy: 0.8975 - val_loss: 0.0481 - val_accuracy: 0.7670\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0120 - accuracy: 0.7886 - val_loss: 0.0078 - val_accuracy: 0.7355\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0069 - accuracy: 0.9027 - val_loss: 0.0047 - val_accuracy: 0.6477\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0104 - accuracy: 0.8118 - val_loss: 0.0065 - val_accuracy: 0.6555\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0095 - accuracy: 0.8205 - val_loss: 0.0148 - val_accuracy: 0.7148\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0065 - accuracy: 0.8697 - val_loss: 0.0403 - val_accuracy: 0.7475\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0071 - accuracy: 0.8481 - val_loss: 0.0410 - val_accuracy: 0.7554\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0069 - accuracy: 0.8182 - val_loss: 0.0161 - val_accuracy: 0.7493\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0047 - accuracy: 0.8670 - val_loss: 0.0083 - val_accuracy: 0.7454\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0066 - accuracy: 0.8927 - val_loss: 0.0080 - val_accuracy: 0.7462\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0068 - accuracy: 0.8951 - val_loss: 0.0127 - val_accuracy: 0.7507\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0055 - accuracy: 0.8762 - val_loss: 0.0263 - val_accuracy: 0.7572\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0054 - accuracy: 0.8426 - val_loss: 0.0329 - val_accuracy: 0.7570\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0058 - accuracy: 0.8512 - val_loss: 0.0205 - val_accuracy: 0.7399\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0042 - accuracy: 0.8980 - val_loss: 0.0153 - val_accuracy: 0.7006\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0051 - accuracy: 0.8968 - val_loss: 0.0185 - val_accuracy: 0.7093\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0046 - accuracy: 0.8960 - val_loss: 0.0276 - val_accuracy: 0.7337\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0042 - accuracy: 0.8957 - val_loss: 0.0333 - val_accuracy: 0.7455\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0045 - accuracy: 0.8915 - val_loss: 0.0252 - val_accuracy: 0.7455\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0038 - accuracy: 0.8986 - val_loss: 0.0181 - val_accuracy: 0.7385\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0039 - accuracy: 0.9096 - val_loss: 0.0171 - val_accuracy: 0.7408\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0040 - accuracy: 0.9123 - val_loss: 0.0224 - val_accuracy: 0.7552\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0036 - accuracy: 0.9046 - val_loss: 0.0311 - val_accuracy: 0.7629\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0040 - accuracy: 0.8941 - val_loss: 0.0260 - val_accuracy: 0.7501\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - accuracy: 0.9110 - val_loss: 0.0209 - val_accuracy: 0.7228\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0037 - accuracy: 0.9133 - val_loss: 0.0224 - val_accuracy: 0.7235\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - accuracy: 0.9147 - val_loss: 0.0292 - val_accuracy: 0.7411\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0034 - accuracy: 0.9118 - val_loss: 0.0306 - val_accuracy: 0.7474\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0034 - accuracy: 0.9056 - val_loss: 0.0240 - val_accuracy: 0.7390\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0032 - accuracy: 0.9125 - val_loss: 0.0222 - val_accuracy: 0.7354\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0032 - accuracy: 0.9137 - val_loss: 0.0253 - val_accuracy: 0.7451\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030 - accuracy: 0.9132 - val_loss: 0.0295 - val_accuracy: 0.7456\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030 - accuracy: 0.9123 - val_loss: 0.0279 - val_accuracy: 0.7279\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0029 - accuracy: 0.9162 - val_loss: 0.0259 - val_accuracy: 0.7170\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0029 - accuracy: 0.9146 - val_loss: 0.0280 - val_accuracy: 0.7353\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0027 - accuracy: 0.9167 - val_loss: 0.0278 - val_accuracy: 0.7489\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0027 - accuracy: 0.9167 - val_loss: 0.0255 - val_accuracy: 0.7350\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0027 - accuracy: 0.9123 - val_loss: 0.0288 - val_accuracy: 0.7496\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026 - accuracy: 0.9149 - val_loss: 0.0269 - val_accuracy: 0.7429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0025 - accuracy: 0.9197 - val_loss: 0.0260 - val_accuracy: 0.7315\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0024 - accuracy: 0.9200 - val_loss: 0.0306 - val_accuracy: 0.7482\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0024 - accuracy: 0.9199 - val_loss: 0.0256 - val_accuracy: 0.7246\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0023 - accuracy: 0.9203 - val_loss: 0.0271 - val_accuracy: 0.7448\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0022 - accuracy: 0.9193 - val_loss: 0.0282 - val_accuracy: 0.7430\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0022 - accuracy: 0.9190 - val_loss: 0.0265 - val_accuracy: 0.7259\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0022 - accuracy: 0.9236 - val_loss: 0.0297 - val_accuracy: 0.7448\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0021 - accuracy: 0.9224 - val_loss: 0.0276 - val_accuracy: 0.7408\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - accuracy: 0.9247 - val_loss: 0.0279 - val_accuracy: 0.7304\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - accuracy: 0.9270 - val_loss: 0.0280 - val_accuracy: 0.7445\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - accuracy: 0.9239 - val_loss: 0.0276 - val_accuracy: 0.7345\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0019 - accuracy: 0.9295 - val_loss: 0.0299 - val_accuracy: 0.7250\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0019 - accuracy: 0.9276 - val_loss: 0.0250 - val_accuracy: 0.7453\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0021 - accuracy: 0.9276 - val_loss: 0.0287 - val_accuracy: 0.7361\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0018 - accuracy: 0.9293 - val_loss: 0.0325 - val_accuracy: 0.7105\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0022 - accuracy: 0.9237 - val_loss: 0.0255 - val_accuracy: 0.7487\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0021 - accuracy: 0.9294 - val_loss: 0.0260 - val_accuracy: 0.7534\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0022 - accuracy: 0.9211 - val_loss: 0.0270 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0018 - accuracy: 0.9344 - val_loss: 0.0344 - val_accuracy: 0.7234\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0023 - accuracy: 0.9303 - val_loss: 0.0249 - val_accuracy: 0.7231\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0020 - accuracy: 0.9285 - val_loss: 0.0296 - val_accuracy: 0.7495\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0022 - accuracy: 0.9149 - val_loss: 0.0261 - val_accuracy: 0.7497\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - accuracy: 0.9270 - val_loss: 0.0238 - val_accuracy: 0.7209\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0019 - accuracy: 0.9343 - val_loss: 0.0327 - val_accuracy: 0.7238\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0019 - accuracy: 0.9318 - val_loss: 0.0323 - val_accuracy: 0.7292\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0017 - accuracy: 0.9344 - val_loss: 0.0258 - val_accuracy: 0.7295\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0017 - accuracy: 0.9398 - val_loss: 0.0268 - val_accuracy: 0.7477\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0017 - accuracy: 0.9351 - val_loss: 0.0290 - val_accuracy: 0.7487\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0017 - accuracy: 0.9306 - val_loss: 0.0279 - val_accuracy: 0.7257\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0015 - accuracy: 0.9387 - val_loss: 0.0295 - val_accuracy: 0.7134\n",
      "INFO:tensorflow:Assets written to: other_files/colorize_autoencoder.model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntf.keras.models.load_model(\\n    \\'other_files/colorize_autoencoder300.model\\',\\n    custom_objects=None,\\n    compile=True)\\nimg1_color=[]\\nimg1=img_to_array(load_img(\\'images/monalisa.png\\'))\\nimg1 = resize(img1 ,(256,256))\\nimg1_color.append(img1)\\nimg1_color = np.array(img1_color, dtype=float)\\nimg1_color = rgb2lab(1.0/255*img1_color)[:,:,:,0]\\nimg1_color = img1_color.reshape(img1_color.shape+(1,))\\noutput1 = model.predict(img1_color)\\noutput1 = output1*128\\nresult = np.zeros((256, 256, 3))\\nresult[:,:,0] = img1_color[0][:,:,0]\\nresult[:,:,1:] = output1[0]\\nimsave(\"result.png\", lab2rgb(result))\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X,Y,validation_split=0.1, epochs=100, batch_size=16)\n",
    "\n",
    "model.save('other_files/colorize_autoencoder.model')\n",
    "\n",
    "###########################################################\n",
    "#Load saved model and test on images.\n",
    "#colorize_autoencoder300.model is trained on 300 epochs\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.models.load_model(\n",
    "    'other_files/colorize_autoencoder.model',\n",
    "    custom_objects=None,\n",
    "    compile=True)\n",
    "img1_color=[]\n",
    "img1=img_to_array(load_img('images/some.jpg'))\n",
    "img1 = resize(img1 ,(256,256))\n",
    "img1_color.append(img1)\n",
    "img1_color = np.array(img1_color, dtype=float)\n",
    "img1_color = rgb2lab(1.0/255*img1_color)[:,:,:,0]\n",
    "img1_color = img1_color.reshape(img1_color.shape+(1,))\n",
    "output1 = model.predict(img1_color)\n",
    "output1 = output1*128\n",
    "result = np.zeros((256, 256, 3))\n",
    "result[:,:,0] = img1_color[0][:,:,0]\n",
    "result[:,:,1:] = output1[0]\n",
    "imsave(\"result.png\", lab2rgb(result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
